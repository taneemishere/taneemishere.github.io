<!DOCTYPE html>
<html lang="en-US">

<head>
    <title>lipsync2: Talking Face Generation with Most Accurate Lip Synchronisation</title>

    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Taneem Jan - My Logs">

    <meta name="keywords" content="deep learning html">

    <link rel="canonical" href="https://taneemishere.github.io/">

    <link rel="icon" type="image/x-icon" href="../images/icon-mod.ico">
    <script async src="../js/analytics.js"></script>
    <script src="../js/favicon-switcher.js" type="application/javascript"></script>

    <link rel="stylesheet" href="../css/academicons.css" crossorigin="anonymous">
    <link rel="stylesheet" href="../css/academicons.min.css" crossorigin="anonymous">

    <link rel="stylesheet" href="../css/all.min.css" crossorigin="anonymous">

    <link rel="stylesheet" href="../css/style.css">
</head>

<body>
    <div class="content" style="font-size: medium">
        <header>
            <p><span><a href="/"><span>Home</span></a></span></p>
        </header>
    </div>
    <div class="wrapper" style="padding-left: 6%;">
        <section style="margin-top: 5%; margin-right: 2%; width: fit-content;">

            <h1 style="text-align: center; font-size: 35px;">
                <span style="color: red;">lipsync2</span>: Talking Face Generation with Most Accurate Lip
                Synchronisation
            </h1>


            <p style="margin-top: 3%; text-align: center;">
                research and development work conducted at BHuman AI <br>by
            </p>

            <div style="display: flex; justify-content: space-around;">
                <strong style="margin: 0; font-size: large;">
                    <!-- <a href="https://taneemishere.github.io">Taneem Ullah Jan <sup>*1</sup></a> -->
                    <a href="https://taneemishere.github.io">Taneem Ullah Jan</a>
                </strong>
            </div>

            <!-- <p style="margin-top: 3%; text-align: center;"><sup>1</sup>
                BHuman AI :: <sup>*</sup>First Author
                <br>research and development work done solely in–house by author</p> -->
                <br><br>
                <div style="display: flex; justify-content: space-around;">
                    <iframe width="460" height="300" src="https://www.youtube.com/embed/iSf1JBZff5E?rel=0"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
    
                    <iframe width="460" height="300" src="https://www.youtube.com/embed/Iv4EjbDoGLk?rel=0"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
                </div>

                <br><br>
            <h2 style="text-align: center; margin-top: 2%;">Highlights</h2>
            <br>
            <p><span style="font-weight: bold;" class="research">the bigger question!</span></p>
            <p style="font-size: large; text-align: justify;">
                Why we call it <i>lipsync2</i>, where's the first one if this is the second...? The anwer is that this
                is our second model in the series of lip synchronisation models. The first one was a great success, but
                it had its limitations, which we've overcome in this version. We've made it more accurate, more robust,
                and more efficient.
            </p>
            <p style="font-size: large; text-align: justify;">
                Embark on an immersive experience with our lip synchronisation model, where we're setting new standards
                in the creation of videos that generate faces talking with accurate lip movements. lipsync2 is our
                answer to the challenges left unsolved in previous works. The first big win is getting the
                synchronisation of ips and speech just right. It's a game-changer because it's key to making the
                characters in the videos convincing. If the lip movements are off, the whole video feels fake; isn't,
                and that's what we've managed to reduce. However, the magic of lipsync2 doesn't end with lip-syncing.
                What makes it extra special is its ability to understand and replicate the full range of facial
                movements from the original video. It's not just about getting the words right; it's about preserving
                the complete expressions and personality. This attention to detail means the end product isn't a tedious
                avatar but a true reflection of the individual's unique way of speaking and expressions.
            </p>
            <p><span style="font-weight: bold;" class="research">what's more!</span></p>
            <p style="font-size: large; text-align: justify;">
                Well, lipsync2 is a good performer when it comes to long audio sequences. Previously,
                models would lack when the audio track was too lengthy, messing up the sync and disrupting the
                video realism. That problem is now in our history, lipsync2 handles long signals of speech with ease,
                keeping everything in sync and maintaining a smooth, natural feel throughout.
            </p>

            <p style="font-size: large; text-align: justify;">
                But there's even more to it. This project wasn't just about fixing bugs or an increment to the previous;
                it was about taking the whole work to a new level. We looked at all the feedback from the first
                version and used it to make something not just better, but innovative. We're talking about a tool that
                transforms the way we produce and perceive digital and personalised communication, making it more vivid
                and enjoyable.
            </p>
            <br><br>

            <div style="display: flex; justify-content: space-around;">
                <iframe width="460" height="300" src="https://www.youtube.com/embed/xYpCn5VF_Q0?rel=0"
                    frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen>
                </iframe>

                <iframe width="460" height="300" src="https://www.youtube.com/embed/srUHaApBUiw?rel=0"
                    frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen>
                </iframe>
            </div>

            <br><br>
            <div style="display: flex; justify-content: space-around;">
                <iframe width="460" height="300" src="https://www.youtube.com/embed/9gjm2bTq6_I?rel=0"
                    frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen>
                </iframe>

                <iframe width="460" height="300" src="https://www.youtube.com/embed/JW5ggTrFACg?rel=0"
                    frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen>
                </iframe>
            </div>

            <br><br>
            <p style="font-size: 12px; text-align: center;">Developed on top of open source &copy;
                Taneem Jan 2019–2024</p>
        </section>
    </div>

    <script src="js/scale.fix.js"></script>

    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date(); a = s.createElement(o),
                m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
        ga('create', 'UA-111540567-4', 'auto');
        ga('send', 'pageview');
    </script>



</body>

</html>