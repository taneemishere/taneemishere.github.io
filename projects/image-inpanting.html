<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">

  <meta property="og:url" content="https://taneemishere.github.io/projects/image-inpanting.html" />
  <meta name="keywords" content="Image Inpainting; GAN; Pixel CNN; LSTM">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Beyond CNNs :: Image Inpainting</title>
  <link rel="icon" type="image/x-icon" href="./static/images/profile/icon-mod.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="../static/css/bulma.min.css">
  <link rel="stylesheet" href="../static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="../static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="../static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="../static/js/fontawesome.all.min.js"></script>
  <script src="../static/js/bulma-carousel.min.js"></script>
  <script src="../static/js/bulma-slider.min.js"></script>
  <script src="../static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"><span style="color: red;">Beyond CNNs</span>: Encoded
              Context for Image Inpainting with LSTMs and Pixel CNNs</h1>
            <br>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://taneemishere.github.io" target="_blank">Taneem Ullah Jan</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="#">Ayesha Noor</a></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">University of Engineering and Technology Peshawar, Pakistan<br>
                <br>International Conference on Innovations in Computing Technologies and
                Information Sciences (ICTIS) 2024 <br> International Journal of Innovations in Science & Technology
                (IJIST) Special Issue</span>
              <br>
              <span class="eql-cntrb"><small><br><sup>*</sup>First Author</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://journal.50sea.com/index.php/IJIST/article/view/783/1369" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://journal.50sea.com/index.php/IJIST/article/view/783" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>IJIST</span>
                  </a>
                </span>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- architecture images -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <img src="../static/images/projects/fig_3.png" alt="autoencoder model" />
            <h2 class="subtitle has-text-centered">
              Autoencoder architecture of our model.
            </h2>
          </div>
          <div class="item">
            <img src="../static/images/projects/fig_10.png" alt="row flattened lstm model" />
            <h2 class="subtitle has-text-centered">
              Row Flattened LSTM Architecture.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Our paper presents some creative advancements in the image in-painting techniques for small, simple images
              for example from the CIFAR10 dataset. This study primarily targeted on improving the performance of the
              context encoders through the utilization of several major training methods on Generative Adversarial
              Networks (GANs). To achieve this, we upscaled the network Wasserstein GAN (WGAN) and compared the
              discriminators and encoders with the current state-of-the-art models, alongside standard Convolutional
              Neural Network (CNN) architectures. Side by side to this, we also explored methods of Latent Variable
              Models and developed several different models, namely Pixel CNN, Row Long Short Term Memory (LSTM), and
              Diagonal Bidirectional Long Short-Term Memory (BiLSTM). Moreover, we proposed a model based on the Pixel
              CNN architectures and developed a faster yet easy approach called Row-wise Flat Pixel LSTM. Our
              experiments demonstrate that the proposed models generate high-quality images on CIFAR10 while conforming
              the L2 loss and visual quality measurement.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">

          <div class="item">
            <img src="../static/images/projects/fig_9.png" width="640" height="360" alt="Pixel CNN model result"
              style="display: block; margin: 0 auto;" />
            <h2 class="subtitle has-text-centered">
              On the left is ground truth example and on the right is a reconstructed image from the Pixel CNN model
            </h2>
          </div>

          <div class="item">
            <img src="../static/images/projects/fig_11.png" width="640" height="360" alt="Row-wise Flat Pixel
            LSTM result" style="display: block; margin: 0 auto;" />
            <h2 class="subtitle has-text-centered">
              On the left is ground truth example and on the right is a reconstructed image from our Row-wise Flat Pixel
              LSTM
            </h2>
          </div>

          <div class="item">
            <img src="../static/images/projects/fig_12.png" width="640" height="360" alt="Final result"
              style="display: block; margin: 0 auto;" />
            <h2 class="subtitle has-text-centered">
              Results from Out-of-sample example
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- paper description -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
            <p>
              <strong>The Problem</strong> <br>
              In the expansive field of computer vision, one challenge has consistently stood out due to its complexity
              and potential impact: image inpainting. This technique, essential in restoring old photographs and
              repairing visual content, involves filling in missing or damaged portions of an image in a way that is
              seamless and unnoticeable. The goal is not just to cover the gaps but to understand the surrounding
              pixels' context and regenerate the lost part in harmony with the whole image. Traditional methods have
              halted in maintaining consistency in texture and color, often leaving noticeable mismatches that fails the
              alterations.
            </p>

            <strong>Innovating image restoration with deep learning</strong> <br>
            <p>Our work sought to advance this process by leveraging deep learning, bringing a nuanced understanding of
              images at a latent level. We delved into the realm of Generative Adversarial Networks (GANs) and
              specifically adapted the network to a Wasserstein GAN (WGAN) framework. This adaptation, coupled with
              strategic training enhancements, fortified our model's ability to handle the softness of image textures
              and colors. Parallelly, our exploration extended into density-based methods, where we experimented with
              Pixel CNN and various LSTM configurations. A significant development was the introduction of a unique
              method we called Flattened Row LSTM, simplifying the traditionally complex architectures. This innovation
              was not just about streamlining but also about enhancing the model's interpretability of the image data.
            </p>

            <strong>Future directions: beyond the frame!</strong>
            <p>While our results are promising, the field of innovation remains vast. Potential future explorations
              include expanding the model's capabilities to handle more complex and higher-resolution images AND videos,
              essential for real-world applications. Furthermore, integrating more advanced GAN and Diffusion
              architectures or delving into unsupervised learning territories could unlock even more sophisticated
              inpainting techniques. Another intriguing area is exploring real-time inpainting for video content, a
              frontier not yet fully charted. This advancement could revolutionize film restoration, live broadcasting,
              and video editing by providing tools to repair visual content on-the-fly.</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- paper slides/poster -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Slides</h2>
        <iframe src="../static/files/Beyond CNNs_ Encoded Context for Image Inpainting with LSTMs and Pixel CNNs.pdf"
          width="100%" height="550">
        </iframe>
      </div>
    </div>
  </section>

  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTex</h2>
      <pre><code>@article{
        Jan_Noor_2024, 
        title={Beyond CNNs: Encoded Context for Image Inpainting with LSTMs and Pixel CNNs}, 
        volume={6}, 
        url={https://journal.50sea.com/index.php/IJIST/article/view/783},  
        number={5}, 
        journal={International Journal of Innovations in Science &amp; Technology}, 
        author={Jan, Taneem Ullah and Noor, Ayesha}, 
        year={2024}, 
        month={May}, 
        pages={165-179} 
      }
      </code></pre>
    </div>
  </section>

  <!-- footer -->
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content" style="text-align: center;">
            <p>
              Website template adapted from <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">here</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>